{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LangChain의 개념과 주요 컴포넌트 이해\n",
    "\n",
    "### **학습 목표:** LangChain의 기본 아키텍처와 주요 컴포넌트를 학습한다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain이란 \n",
    "\n",
    "핵심 내용:\n",
    "- **LangChain**은 LLM 기반 애플리케이션 개발을 위한 프레임워크\n",
    "\n",
    "- **Chain**은 작업을 순차적으로 실행하는 파이프라인 구조를 제공\n",
    "\n",
    "- **Agent**는 자율적 의사결정이 가능한 실행 단위\n",
    "\n",
    "결론:\n",
    "- LangChain은 Chain과 Agent라는 두 가지 핵심 기능을 통해 LLM 애플리케이션 개발을 효율적으로 지원\n",
    "\n",
    "\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"https://python.langchain.com/svg/langchain_stack_112024_dark.svg\" \n",
    "            alt=\"langchain_stack\" \n",
    "            width=\"600\" \n",
    "            style=\"border: 0;\">\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain 컴포넌트 \n",
    "\n",
    "핵심 내용:\n",
    "- LangChain **주요 컴포넌트**: LLM/ChatModel, Prompt, Memory, Tool, Document Loader, Text Splitter, Embedding, Vectorstore\n",
    "\n",
    "- **언어 처리 기능**은 LLM/ChatModel이 중심이 되며, Prompt와 Memory로 대화를 관리\n",
    "\n",
    "- **문서 처리와 검색**은 Document Loader, Text Splitter, Embedding, Vectorstore가 담당\n",
    "\n",
    "- **모듈성**이 핵심 특징으로, 독립적인 컴포넌트들을 조합해 RAG와 같은 복잡한 시스템을 구현 가능 \n",
    "\n",
    "결론:\n",
    "- Tool을 통한 확장성과 컴포넌트의 재사용성으로 다양한 LLM 애플리케이션 개발이 가능\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 변수 로드\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 모델 (Models)\n",
    "- LLM, ChatModel 등으로 구분\n",
    "- OpenAI, Anthropic, Google 등 다양한 모델을 지원\n",
    "- 텍스트 생성, 대화, 요약 등의 작업을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "response = model.invoke(\"안녕하세요!\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답변 출력\n",
    "print(\"답변: \", response.content)\n",
    "print(\"메타데이터: \", response.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 메시지 (Messages)\n",
    "- Chat Model에서 사용할 수 있는 통합된 메시지 형식을 제공\n",
    "- 각 모델 제공자의 특정 메시지 형식을 신경 쓰지 않고도 다양한 채팅 모델을 활용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. HumanMessage`\n",
    "- 사용자 역할에 해당\n",
    "- 사용자의 입력을 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 사용자 메시지 생성\n",
    "human_message = HumanMessage(content=\"Glory를 한국어로 번역해주세요.\")\n",
    "\n",
    "# 번역 요청\n",
    "response = model.invoke([human_message])\n",
    "\n",
    "# 답변 출력\n",
    "print(\"답변: \", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열을 입력하면, 자동으로 HumanMessage로 변환하여 요청\n",
    "model.invoke(\"Glory를 한국어로 번역해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. AIMessage`\n",
    "- AI 모델의 응답을 표현\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI 모델의 응답 객체를 출력 \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 응답 텍스트 부분을 출력\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 사용량 출력\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. SystemMessage`\n",
    "- 시스템 역할에 해당\n",
    "- AI 모델의 동작과 제약사항을 정의하는데 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage \n",
    "\n",
    "# 시스템 메시지 생성\n",
    "system_msg = SystemMessage(content=\"당신은 영어를 한국어로 번역하는 AI 어시스턴트입니다.\")\n",
    "\n",
    "system_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 요청\n",
    "human_message = HumanMessage(content=\"Glory\")\n",
    "\n",
    "messages = [system_msg, human_message]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "\n",
    "# 답변 출력\n",
    "print(\"답변: \", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 프롬프트 템플릿 (Prompt Template)\n",
    "- 프롬프트 템플릿을 통해 일관된 입력 형식을 제공\n",
    "    1. 사용자의 입력과 파라미터를 언어 모델이 이해할 수 있는 형태로 변환하는 도구\n",
    "    2. 언어 모델에게 전달할 지시문을 만드는 틀\n",
    "- 변수를 포함한 동적 프롬프트 생성이 가능\n",
    "    1. 모든 템플릿은 딕셔너리 형태의 입력을 받아서 처리\n",
    "    2. 출력은 PromptValue 형태로 반환되며, 이는 문자열이나 메시지 리스트로 변환 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. 문자열 프롬프트 템플릿 (String PromptTemplate)`\n",
    "- 가장 기본적인 형태\n",
    "- 단일 문자열을 형식화하는데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 템플릿 생성\n",
    "template = PromptTemplate.from_template(\"{주제}에 대한 이야기를 해줘\")\n",
    "\n",
    "# 템플릿 사용\n",
    "prompt = template.invoke({\"주제\": \"고양이\"})\n",
    "\n",
    "# 출력\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2. 채팅 프롬프트 템플릿 (ChatPromptTemplate)`\n",
    "- 여러 메시지를 포함하는 대화형 템플릿을 만들 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 채팅 템플릿 생성\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 도움이 되는 비서입니다\"),\n",
    "    (\"user\", \"{subject}에 대해 설명해주세요\")\n",
    "])\n",
    "\n",
    "# 템플릿 사용\n",
    "prompt = template.invoke({\"subject\": \"인공지능\"})\n",
    "\n",
    "# 출력\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3. 메시지 플레이스홀더 (MessagesPlaceholder)`\n",
    "- 기존 메시지 목록을 템플릿의 특정 위치에 삽입할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 메시지 플레이스홀더가 있는 템플릿\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 도움이 되는 비서입니다\"),\n",
    "    MessagesPlaceholder(\"chat_history\")\n",
    "])\n",
    "\n",
    "# 템플릿 사용\n",
    "prompt = template.invoke({\n",
    "    \"chat_history\": [HumanMessage(content=\"안녕하세요!\")]\n",
    "})\n",
    "\n",
    "# 출력\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 출력 파서 (Output Parser)\n",
    "1. **역할과 기능**\n",
    "    - 모델의 텍스트 출력을 구조화된 데이터로 변환\n",
    "    - 채팅 모델과 LLM의 출력을 정규화\n",
    "    - 다운스트림 작업을 위한 데이터 형식 변환\n",
    "\n",
    "2. **사용 시 고려사항**\n",
    "    - OpenAI function calling과 같은 기능이 있는 경우, 해당 기능을 우선 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 기본적인 문자열 파서 사용\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = PromptTemplate.from_template(\"도시 {city}의 특징을 알려주세요\")\n",
    "\n",
    "# 모델 정의\n",
    "model = ChatOpenAI(model='gpt-4.1-mini')\n",
    "\n",
    "# 체인 구성\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# 체인 실행\n",
    "result = chain.invoke({\"city\": \"서울\"})\n",
    "\n",
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 메모리 (Memory)\n",
    "- 대화 기록을 저장하고 관리\n",
    "- 컨텍스트 유지를 위한 다양한 메모리 타입을 제공\n",
    "- 대화 요약, 버퍼링 등의 기능을 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# 메모리 기반 히스토리 구현\n",
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    \n",
    "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
    "        self.messages.extend(messages)\n",
    "    \n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "\n",
    "# 세션 저장소\n",
    "store = {}\n",
    "\n",
    "# 세션 ID로 히스토리 가져오기\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채팅 모델과 프롬프트 설정\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 {subject}에 능숙한 비서입니다\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | ChatOpenAI(model='gpt-4.1-mini')\n",
    "\n",
    "# 히스토리 관리 추가\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# 체인 실행\n",
    "response = chain_with_history.invoke(\n",
    "    {\"subject\": \"수학\", \"question\": \"1+2는 얼마인가요?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}}\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션 ID로 히스토리 가져오기\n",
    "get_session_history(\"user1\").messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 히스토리 이용해서 대화 진행\n",
    "response = chain_with_history.invoke(\n",
    "    {\"subject\": \"수학\", \"question\": \"여기에 숫자 2를 곱하면 얼마인가요?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}}\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션 ID로 히스토리 가져오기\n",
    "get_session_history(\"user1\").messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [실습]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 새로운 채팅 세션(\"student1\")을 만들고, 수학 문제를 해결하는 대화를 2회 이상 진행해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 다음 조건을 만족하는 새로운 ChatPromptTemplate을 만드세요.\n",
    "   - 시스템 메시지: \"당신은 친절한 과학 선생님입니다\"\n",
    "   - 대화 기록을 포함\n",
    "   - 사용자 질문을 받을 수 있는 형식\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. StrOutputParser를 사용하여 다음을 구현해보세요.\n",
    "   - 앞의 프롬프트 템플릿을 사용하여 체인 구성 및 실행\n",
    "   - \"섭씨온도와 화씨온도 관계\"를 설명해 달라고 요청하는 프롬프트 작성 \n",
    "   - 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
